## Lecture2

### Image Classification Pipeline

```train``` : pre-determining set of labels

-> ```predict``` : assign one label among training dataset labels



#### Problems

- Illumination : lighting condition

- Deformation
- Occlusion
- Background clutter
- Intraclass variation in ```color, shape, etc```

>  e.g.

>  Semantic Gap : difference in pixel values

> + when camera changes -> pixel changes

ðŸ‘‡

*hard to predicting simultaneously*



### An image classifier

1. find edges

2. find corners

*compute the edges ðŸ‘‰ find corners*

>  problem : start over again with diff objects



### Data-driven Approach

1. large dataset ( e.g. google image search )

2. machine learning classifier

3. evaluate

ðŸ‘‡

two functions : ```train``` + ```predict```

1. train : input images + labels
2. predict : input model ðŸ‘‰ output prediction



#### First classifier : Nearest Neighbor

- ```train``` : memorize all the data and labels = O(1)

- ```predict``` : find the most similar training image = O(n)

##### Example Dataset: CIFAR10

##### Distance Metric to compare images : L1 Distance

> sum up the absolute values of the points



> Q. With N examples, how fast are training and prediciton?
>
> A. Train O(1), predict O(N)

â—ï¸it should be opposite : fastify a prediction (training doesn't matter)

â—ï¸wanna extend to mobile, or any device

â—ï¸wrong decision regions



### K-Nearest Neighbors

take majority vote from K closest points

ðŸ‘‰ smoothe out the decision boundary



![kNN](https://user-images.githubusercontent.com/40735375/50537854-fc7d6b80-0ba8-11e9-9045-937ce1884a5c.png)

k = 1; í•˜ë‚˜ì˜ ë°ì´í„°ì— ì˜ì¡´í•´ì„œ ë¯¸ì„¸í•œ ë³€í™”ì—ë„ ì‰½ê²Œ ì˜í–¥ì„ ë°›ê²Œëœë‹¤.

k = 3; ì´ˆë¡ìƒ‰ì˜ ì˜ì—­ í•œ ê°€ìš´ë°ì— ìžˆë˜ ë…¸ëž€ìƒ‰ì˜ ì˜ì—­ì´ ì‚¬ë¼ì§„ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìžˆë‹¤. ê·¸ëŸ¼ì—ë„ ì•„ì§ ë¹¨ê°•-íŒŒëž‘ì˜ ê²½ê³„ëŠ” ë“¤ì‘¥ë‚ ì‘¥í•œ ê²ƒì„ ì•Œ ìˆ˜ ìžˆë‹¤.

k = 5; ë“¤ì‘¥ë‚ ì‘¥í•˜ë˜ ê²½ê³„ë„ ì‚¬ë¼ì§„ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìžˆë‹¤.



#### Distance Metric

*__specifying each data into ```different distance metrics```__*

*__ðŸ‘‰ can ```compare``` any type of data__*

1. L1 (Manhattan) distance

   * **coordinate dependency** ðŸ‘‰ changing coordinate point matters

   * if every partition in points has its own meaning

2. L2 (Euclidean) distance

   * don't know the actual meaning of individual partitions
   * but if the feature(point) has the meaning in its space



![L1_L2](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fo1iTy%2FbtqCOfgbW76%2Fxv5PL4KWIDdrHAnvXdzTKK%2Fimg.png)

>  green : Euclidean, L2 distance
>
> others : L1 distance



ðŸ‘‡

```kì˜ ê°’ì„ ë¬´ì—‡ìœ¼ë¡œ ì„¤ì •í•˜ëŠëƒ```ì— ë”°ë¼ì„œ ëª¨ë¸ì´ ë‚´ë†“ëŠ” ê²°ê³¼ ê°’ì´ ë‹¬ë¼ì§€ê²Œ ëœë‹¤. ê·¸ë¦¬ê³  ë‘ ê°€ì§€ì˜ ê±°ë¦¬ ê³µì‹ ì¤‘ì—ì„œë„ ```ì–´ë–¤ ê±°ë¦¬ ê³µì‹ì„ ì‚¬ìš©í•˜ëŠëƒ```ì— ë”°ë¼ì„œ ê²°ê³¼ ê°’ì´ ë‹¬ë¼ì§€ê²Œ ëœë‹¤. ì´ë ‡ë“¯ ```ë°ì´í„°ë¡œë¶€í„° í•™ìŠµì„ í†µí•´ ì–»ì–´ì§€ëŠ” íŒŒë¼ë¯¸í„°ë“¤ì´ ì•„ë‹ˆë¼,``` ì•Œê³ ë¦¬ì¦˜ê³¼ ë°ì´í„°ì˜ ì„±ê²©ì— ë”°ë¼ì„œ ```ìš°ë¦¬ê°€ ê²°ì •í•´ì•¼ í•˜ëŠ” íŒŒë¼ë¯¸í„°ë“¤```ì„ __*hyperparameters*__ë¼ê³  í•œë‹¤. 

ë¬¸ì œì˜ ì„±ê²©ì— ë”°ë¼ì„œ ì ì ˆí•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ê°€ ë§¤ìš° ë‹¬ë¼ì§€ê¸° ë•Œë¬¸ì— ì—¬ëŸ¬ê°€ì§€ë¥¼ ì‹¤í—˜í•´ë³´ê³  ê°€ìž¥ ì„±ëŠ¥ì´ ì¢‹ì€ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì„ íƒí•´ì•¼ í•œë‹¤.

***



#### HyperParameters

> K, distance metric, etc...

* trainingì„ ìœ„í•´ ë¯¸ë¦¬ ì„¤ì •, ì „ë‹¬í•˜ëŠ” parameter

* not necessarily learned from the training data

* no way to learn directly from the data
* **problem-dependent** ðŸ‘‰ try different values to find out the best choice

* **choices about the algorithm that we set rather than learn**
* e.g. try both L1, L2 distance and choose



##### Setting Hyperparameters

**Idea1** Choosing hyperparameters that work best on the full dataset

ðŸ’¥ ```overfitting``` : K=1 always works the best, but makes the worst output to the unseen dataset; ëª¨í˜•ì€ ë§Œë“¤ì–´ëƒˆì§€ë§Œ, ëª¨í˜•ì˜ ì„±ëŠ¥ì„ ```í‰ê°€í•  ìˆ˜ ì—†ë‹¤```. ê¸°ì¡´ì˜ ë°ì´í„° ì…‹ì— ëŒ€í•´ì„œëŠ” ì™„ë²½í•˜ê²Œ ìž‘ë™í•˜ê² ì§€ë§Œ, ìƒì„±ëœ ëª¨í˜•ì´ ì¢‹ì€ì§€ ì•ˆì¢‹ì€ì§€ ì•Œ ìˆ˜ ì—†ë‹¤.



**Idea2** Splitting data into train and test; choose the best one for the test data

ðŸ’¥ Same with choosing one kind of answer that best fits to the test data, again can't be applied to the unseen dataset; í‰ê°€ë¥¼ ìœ„í•´ ì‚¬ìš©í•´ì•¼í•  í…ŒìŠ¤íŠ¸ ì…‹ì´ ```í•˜ì´í¼íŒŒë¼ë¯¸í„° ì í•©ì— ì‚¬ìš©ëœë‹¤```. testing setì— ëŒ€í•œ ì˜ˆì¸¡ê²°ê³¼ë¥¼ ë³´ê³  í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì ˆí•˜ê¸° ë•Œë¬¸ì— testing set ì—­ì‹œ í•™ìŠµì— ì´ìš©í•˜ëŠ” ì…ˆì´ ëœë‹¤. ë”°ë¼ì„œ ë” ì´ìƒ testing setì— ëŒ€í•œ ê²°ê³¼ê°€ ì™„ì „ížˆ ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•œ ê²°ê³¼ë¥¼ ëŒ€í‘œí•˜ì§€ ëª»í•˜ê²Œ ëœë‹¤.

> - **1)** Split the data at hand into training and test subsets
> - **2)** Repeat optimization loop a fixed number of times or until a condition is met:
>   - **a)** Select a new set of model hyperparameters
>   - **b)** Train the model on the training subset using the selected set of hyperparameters
>   - **c)** Apply the model to the test subset and generate the corresponding predictions
>   - **d)** Evaluate the test predictions using the appropriate scoring metric for the problem at hand, such as accuracy or mean absolute error. Store the metric value that corresponds to the selected set of hyperparameters
> - **3)** Compare all metric values and choose the hyperparameter set that yields the best metric value



**Idea3** Splitting data into train, validation, test data; choose the best one for the test data, and again debug things in the test data

![idea3](https://losskatsu.github.io/assets/images/ml/validation/validation05.jpg)

ëª¨í˜•ì˜ ```íŒŒë¼ë¯¸í„° ì¶”ì •ì—ëŠ” íŠ¸ë ˆì´ë‹ì…‹ì„``` ì‚¬ìš©í•˜ê³ , ```í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •ì—ëŠ” ë°¸ë¦¬ë°ì´ì…˜ ì…‹ì„``` ì‚¬ìš©í•œë‹¤. ê·¸ë¦¬ê³  ë§ˆì§€ë§‰ìœ¼ë¡œ ```í…ŒìŠ¤íŠ¸ì…‹```ì— ëª¨í˜•ì„ ì ìš©ì‹œì¼œ ë‹¨ í•œë²ˆë§Œ ì‹¤í—˜í•œ í›„ ì •í™•ë„ë¥¼ ì¸¡ì •í•œë‹¤.

> can't access to the validation dataset, only can check the labels if the algorithm is doing well

> equally distributing the dataset to make the test data representative the wild data
>
> : use the same methodology to collect the data, randomly distributing that to make well-distributed separate dataset



**Idea4** Cross-Validation; splitting into train, test dataset; again splitting the train dataset into multiple folds and cycle through all the fold datasets, choose the best hyperparameter and go into the test dataset

> ë°ì´í„°ì…‹ì´ ì ê³ , unbalanced dataì¼ ê²½ìš° ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì¸ë‹¤.

![val](https://losskatsu.github.io/assets/images/ml/validation/validation06.jpg)

ë¨¼ì € ë°ì´í„°ë¥¼ training setê³¼ testing setìœ¼ë¡œ ë‚˜ëˆˆ í›„ì—, training setì„ kê°œë¡œ ë‚˜ëˆ„ì–´ì„œ ê°ê°ì˜ ì¡°ê°ì— ëŒ€í•´ì„œ í•œë²ˆì”© validationìœ¼ë¡œ ì‚¬ìš©í•˜ë©´ì„œ í•™ìŠµì„ ì§„í–‰í•œë‹¤; íŠ¸ë ˆì´ë‹ì„ kë“±ë¶„í•˜ê³  validation setì„ ì—¬ëŸ¬ë²ˆ ë°”ê¿”ê°€ë©° ë°˜ë³µì ìœ¼ë¡œ ì‹œí–‰í•˜ëŠ” ë°©ë²•ì„ k-fold cross validationì´ë¼ê³  í•œë‹¤.

![result](https://cs231n.github.io/assets/cvplot.png)

5-fold cross-validation accuracy with different k value for kNN,

5 results (cases) for each k value (5-fold)

![overview](https://losskatsu.github.io/assets/images/ml/validation/validation07.jpg)

ðŸ’¥ ë°ì´í„°ì…‹ì˜ ì ˆëŒ€ì ì¸ ì–‘ì´ ì ì„ ë•Œ ì£¼ë¡œ ì‚¬ìš©í•˜ì§€ë§Œ, impractical for deep learning problems; too large data to use this, high computational cost



#### Problem

1. distance between feature vectors (represents each picture) sometimes can not represent perceptual differences, can not capture the full differences between images because it only considers the single distance metric.

   í•˜ì§€ë§Œ ê° í”½ì…€ê°„ì˜ ê±°ë¦¬ë¥¼ êµ¬í•œ í›„ì— ê·¸ ê±°ë¦¬ì˜ ì´í•©ì´ ì ì„ ìˆ˜ë¡ ì´ë¯¸ì§€ê°€ ë¹„ìŠ·í•  ê²ƒì´ë¼ëŠ” ì¶”ë¡ ì€ ì–¸ëœ» ë“£ê¸°ì—ë„ í•©ë¦¬ì ì´ì§€ ì•Šë‹¤. kNNì˜ ì•„ì´ë””ì–´ ìžì²´ê°€ ì´ë¯¸ì§€ ë°ì´í„°ì˜ íŠ¹ì„±ê³¼ëŠ” ê±°ë¦¬ê°€ ë©€ê¸° ë•Œë¬¸ì— kNNìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜í•˜ì§€ëŠ” ì•ŠëŠ”ë‹¤.

![prob1](https://www.pyimagesearch.com/wp-content/uploads/2016/08/knn_animal_clusters.jpg)

> kNN classifier : dist between blue-red circle >>> dist between pics inside the  circles



2. curse of dimensionality

   > each pixel : each vector is gathered
   >
   > => picture itself : high dimensional vector

   * use each data as the partition of the space 

   * need many data to cover the high dimensional space ðŸ‘‰ otherwise, not similar to real data

![prob2](https://images.deepai.org/glossary-terms/curse-of-dimensionality-61461.jpg)

> The volume of the space represented grows so quickly, but the amount of the data is the same. 
>
> As the data space seen above moves from one dimension to two dimensions and finally to three dimensions, the given data fills less and less of the data space. 

  

3. Takes too much time because it takes all the images as the input data for training

***

   

### Linear Classification

the basic for Neural Networks

```linear classification``` : lego block

```neural network``` : lego building



![li](https://t1.daumcdn.net/cfile/tistory/999181485B5820280D)

xiëŠ” ì´ë¯¸ì§€ë¥¼ 1ì°¨ì›ì˜ vectorë¡œ ë§Œë“  í˜•íƒœì´ë©°, yiëŠ” ê·¸ ì´ë¯¸ì§€ì˜ labelì„ ê°€ë¦¬í‚¤ëŠ” ê°’ì´ë¼ê³  í•˜ìž. (10 classë©´, one hot encodingìœ¼ë¡œ í•˜ë‚˜ ê°’ì„ ê°–ê²Œ ëœë‹¤.) linear classifierëŠ” ìž…ë ¥ê³¼ ì¶œë ¥ ì‚¬ì´ì˜ ê´€ê³„ë¥¼ 'ì„ í˜•'ìœ¼ë¡œ ë‚˜íƒ€ë‚¸ ê²ƒì´ë‹¤.

WëŠ” ê° classì˜ classifierë¥¼ í•™ìŠµì„ í•˜ëŠ” ê²ƒì´ë‹¤. ì¦‰, Wì˜ ê° í–‰ì€ ê°ê°ì˜ classë¥¼ êµ¬ë¶„í•˜ëŠ” ê²ƒì„ í•™ìŠµí•˜ëŠ” ê²ƒì´ë‹¤. BiasëŠ” ì´ ì„ ë“¤ì´ í‰í–‰ì´ë™ì„ í•˜ë„ë¡ í•´ì¤€ë‹¤. (ëŒ€ë¶€ë¶„ì˜ linear classifierëŠ” ì–´ë–¤ classì™€ ê·¸ ì™¸ classë¥¼ êµ¬ë¶„ì§“ëŠ” 'hyperplane'ì„ ì°¾ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•œë‹¤. ê·¸ë¦¬ê³  biasëŠ” ì´ ì„ ì„ í‰í–‰ì´ë™ì„ ì‹œí‚¤ëŠ” ê²ƒì´ë‹¤.)

templateì™€ ë§¤ì¹­ë˜ëŠ” ê°’ì„ í•™ìŠµí•œë‹¤ëŠ” ê²ƒì€, ì–´ë–¤ classë¥¼ ë¶„ë¥˜í•  ë•Œ ê·¸ classì™€ ë¹„ìŠ·í•˜ë„ë¡ weightë“¤ì´ í•™ìŠµì´ ëœë‹¤ëŠ” ê²ƒì´ë‹¤. ë§Œì•½ ì´ classì™€ ë¹„ìŠ·í•œ ê·¸ë¦¼ì´ ì˜¤ë©´ ê·¸ weightì€ ìž˜ ë°˜ì‘ (ê°’ì´ í¼)í•´ì„œ (activation) scoreë¥¼ ë†’ì¸ë‹¤. ë”¥ëŸ¬ë‹ì—ì„œëŠ” ì´ templateì´ ìŠ¤ìŠ¤ë¡œ í•™ìŠµì´ ëœë‹¤.



### Parametric Approach



> **Difference between KNN and parametric approach**
>
> 1. KNN : data-driven ðŸ‘‰ use data in test
>
> 2. parametric approach : summarize [training] the knowledge of the data into W and use it in test ðŸ‘‰ time-efficient
>
>    linear classifierì˜ ê²½ìš°ì—ëŠ” í•™ìŠµì„ í†µí•´ì„œ parameterê°€ ì •í•´ì§„ë‹¤ëŠ” ì ì´ ì•žì„œ ë°°ì› ë˜ kNNê³¼ëŠ” ë‹¤ë¥´ë‹¤.



1. ```x``` : input image, works as a template

2. ```W``` : weights / parameters / data

3. ```f``` : combining the ```x``` with data

   in this case, **```f``` => linear classifier** : f(x, W) = Wx

   > f(x, W) = Wx + b
   >
   > => ```b``` : bias towards the expecting class result

```
32x32 í”½ì…€ ì‚¬ì´ì¦ˆë¥¼ ê°€ì§€ëŠ” RGBì´ë¯¸ì§€ë¥¼ 10ê°œì˜ í´ëž˜ìŠ¤ë¡œ ë¶„ë¥˜í•˜ëŠ” ìž‘ì—…ì„ ì‹œë„í•œë‹¤ê³  í•˜ìž. ì´ ë•Œ ìš°ë¦¬ê°€ ìµœì¢…ì ìœ¼ë¡œ êµ¬í•˜ë ¤ê³  í•˜ëŠ” ê²ƒì€ 10ê°œì˜ í´ëž˜ìŠ¤ì— ëŒ€í•œ ê°’ì´ë¯€ë¡œ f(x,W) ëŠ” 10x1ì˜ í¬ê¸°ê°€ ë  ê²ƒì´ë‹¤. ê·¸ë¦¬ê³  ì¸í’‹ì€ ì´ë¯¸ì§€ í•œ ìž¥ì´ë¯€ë¡œ 3072(32*32*3)x1 ì´ë‹¤.
// x : 32 * 32 * 3 = 3072 * 1
// f(x, W) : 10 * 1

ë”°ë¼ì„œ Wì˜ ì ì ˆí•œ í¬ê¸°ëŠ” 10x3072ê°€ ëœë‹¤.
b ëŠ” biased termìœ¼ë¡œ f(x,W) ê³¼ ë™ì¼í•œ 10x1ì˜ í¬ê¸°ë¥¼ ê°€ì§„ë‹¤.
Task : make 10 class of scores(f) from input(x)
Answer : need 10 classes(images) with size 32 * 32 * 3,
W = 10 * 3072, b = 10 * 1
```



![linear](http://aikorea.org/cs231n/assets/imagemap.jpg)

```input image``` : 2 * 2 pixel --> x = 4 * 1

```class (different pictures)``` : 3 classes with 2 * 2 pixels --> W = 3 * 4

```bias``` : 



*higher score == larger possibility to be the answer*

ðŸš€ coming out with the best ```f``` is the actual task for the deep learning



#### Problem

1. learn from only one template per category

2. one linear classifier -> seperate into only two categories,

   thus if there are more than 2 categories, one linear is not enough to work fully as the classifier

   * 4 quarters
   * circle catogory with 'others' category

   * multi-modal

